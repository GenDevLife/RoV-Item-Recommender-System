import sys
import os
import json
import pandas as pd
import numpy as np

# ==========================================
# 1. Setup Paths
# ==========================================
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(PROJECT_ROOT)

from app.config import DB_PATH
from app.data.repository import RoVRepository
from app.core.evaluator import BuildEvaluator

# Config Files
CSV_PATH = os.path.join(PROJECT_ROOT, 'data', 'raw', 'test_fitness.csv')
OUTPUT_WEIGHTS_PATH = os.path.join(PROJECT_ROOT, 'app', 'core', 'learned_weights.json')

# Features ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏ô‡πÉ‡∏à (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö keys ‡πÉ‡∏ô calculate_stats ‡∏Ç‡∏≠‡∏á evaluator)
FEATURE_NAMES = [
    'p_atk', 'm_power', 'max_hp', 'p_def', 'm_def',
    'cdr', 'aspd', 'crit_rate', 'p_pierce_percent', 'm_pierce_percent', 'move_speed'
]

# ==========================================
# 2. Helper Functions
# ==========================================
def load_data(csv_path):
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"‚ùå Training data not found at: {csv_path}")
    return pd.read_csv(csv_path)

def extract_features(row, evaluator, all_items):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 1 ‡πÅ‡∏ñ‡∏ß‡πÄ‡∏õ‡πá‡∏ô Feature Array"""
    build_ids = []
    for i in range(1, 7):
        item_val = row.get(f'Item{i}')
        found_id = None
        
        # Logic ‡∏Å‡∏≤‡∏£‡∏´‡∏≤ ID ‡πÑ‡∏≠‡πÄ‡∏ó‡∏°
        if pd.notna(item_val):
            item_code = str(item_val).strip()
            # Match by item_code (I001, I002, ...)
            for iid, data in all_items.items():
                if data.get('item_code') == item_code:
                    found_id = iid
                    break
        
        if found_id and found_id in all_items:
            build_ids.append(found_id)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Stat ‡∏£‡∏ß‡∏°
    stats = evaluator.calculate_stats(build_ids)
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏° FEATURE_NAMES
    return [stats.get(k, 0.0) for k in FEATURE_NAMES]

# ==========================================
# 3. Math & Algorithms
# ==========================================
def ridge_regression(X, y, alpha=1.0):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Ridge Regression: w = (X^T X + alpha*I)^-1 X^T y
    ‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Multicollinearity (Stat ‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á)
    """
    n_features = X.shape[1]
    I = np.eye(n_features)
    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Bias (column ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢) ‡πÇ‡∏î‡∏ô Penalize
    I[-1, -1] = 0 
    
    # w = inv(X'X + aI) * X'y
    weights = np.linalg.inv(X.T @ X + alpha * I) @ X.T @ y
    return weights

def run_calibration():
    print("üöÄ Starting Advanced Calibration...")
    
    # 1. Init System
    try:
        repo = RoVRepository(DB_PATH)
        all_items = repo.get_all_items()
        dummy_hero = {'base_atk': 0, 'base_def': 0, 'base_hp': 0, 'damage_type': 'Physical'}
        evaluator = BuildEvaluator(dummy_hero, all_items)
    except Exception as e:
        print(f"‚ùå System Init Error: {e}")
        return

    # 2. Load & Prepare Data
    try:
        df = load_data(CSV_PATH)
        print(f"üì• Loaded {len(df)} records.")
        
        X_raw = []
        y = []
        
        for _, row in df.iterrows():
            feats = extract_features(row, evaluator, all_items)
            X_raw.append(feats)
            y.append(row['WinRate'])
            
        X_raw = np.array(X_raw)
        y = np.array(y)
        
        # --- Step 3: Standardization (Normalize Data) ---
        # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏∏‡∏Å Stat ‡∏°‡∏µ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô "Standard Deviation" (‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 0, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á 1)
        # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ OLS/Ridge ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á
        mean = np.mean(X_raw, axis=0)
        std = np.std(X_raw, axis=0)
        
        # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ 0 (‡∏Å‡∏£‡∏ì‡∏µ Stat ‡∏ö‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏´‡∏°‡∏î‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ü‡∏•‡πå)
        std[std == 0] = 1.0 
        
        X_norm = (X_raw - mean) / std
        
        # Add Bias Column (Intercept)
        ones = np.ones((X_norm.shape[0], 1))
        X_final = np.hstack([X_norm, ones])
        
    except Exception as e:
        print(f"‚ùå Data Error: {e}")
        import traceback; traceback.print_exc()
        return

    # 4. Train Model (Ridge Regression)
    print("üßÆ Calculating Weights (Ridge Regression)...")
    try:
        # Alpha ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏î overfitting (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ 0.1 - 10.0)
        weights_norm = ridge_regression(X_final, y, alpha=2.0)
        
        # 5. Analyze & Un-normalize
        # ‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ Weight ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Norm ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà Evaluator ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö
        # ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö: w_raw = w_norm / std
        
        final_weights_raw = {}
        
        print("\n=== üìä Feature Importance (Normalized) ===")
        print("*(‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ Stat ‡πÑ‡∏´‡∏ô‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ä‡∏ô‡∏∞‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)*")
        print("-" * 40)
        
        w_feats_norm = weights_norm[:-1] # ‡∏ï‡∏±‡∏î Bias ‡∏≠‡∏≠‡∏Å
        
        # ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤
        feature_importance = list(zip(FEATURE_NAMES, w_feats_norm, std))
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢)
        feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)
        
        for name, w_norm, s in feature_importance:
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô Raw Weight
            w_raw = w_norm / s
            final_weights_raw[name] = float(w_raw)
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡πà‡∏≤ Norm ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç, ‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡πà‡∏≤ Raw ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á)
            print(f"{name:<20} | Importance: {w_norm:>7.4f} | Raw Weight: {w_raw:>10.6f}")

        # Bias Calculation (‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÄ‡∏°‡∏∑‡πà‡∏≠ Un-normalize ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô GA)
        bias_norm = weights_norm[-1]
        # bias_raw = bias_norm - sum((w_norm * mean) / std)
        
        # 6. Save
        with open(OUTPUT_WEIGHTS_PATH, 'w') as f:
            json.dump(final_weights_raw, f, indent=4)
            
        print("-" * 40)
        print(f"üíæ Saved optimized weights to: {OUTPUT_WEIGHTS_PATH}")
        print("‚úÖ Calibration Complete! Run 'python -m app.main' to test recommendations.")

    except Exception as e:
        print(f"‚ùå Calculation Error: {e}")
        import traceback; traceback.print_exc()

if __name__ == "__main__":
    run_calibration()